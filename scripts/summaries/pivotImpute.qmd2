---
title: Imputing and pivoting
author: Christian Coffman
date: today
format:
  html:
    code-fold: true
    toc: true
    embed-resources: false
project:
  execute-dir: project
execute:
  warning: false
  error: false
  cache: false 
---



```{r setup}
<<<<<<< HEAD
#| label: tbl-dlimpute
#| tbl-cap: "Missing and nonmissing counts for each analyte before imputation."

=======
# ************ NONE OF THIS CODE HAS BEEN REVIEWED YET **************
>>>>>>> initialCodeReview

library(tidyverse)
library(devtools)
load_all()
df <- readRDS("../../fullData.Rds") %>% 
  filter(!grepl("no result", Orig_QAcomment, ignore.case = T)) %>%
  # some values are missing and don't have QA codes nor comments
  filter(
    !is.na(RESULT) | 
    !is.na(Orig_QAcode) |
    !is.na(Orig_QAcomment) |
    !is.na(Orig_QAdefinition) |
    !is.na(Unified_Flag) |
    !is.na(Unified_Comment)
  ) %>%
  # some missed qa actions not filtered
  filter(
    !grepl("invalid", Orig_QAcomment, ignore.case = T),
    !grepl("NRR", Orig_QAcomment, ignore.case = T),
  ) %>% 
  # sometimes unrelated QAcodes retain sample so removing that for Secchi
  #filter(
  #  !(is.na(RESULT) & CodeName == "Secchi" & grepl("T", Orig_QAcomment, ignore.case = T)),
  #) %>% 
  tidyr::drop_na(Latitude, sampleDateTime, CodeName)

df %>% 
  reframe(
    measureCount = sum(!is.na(RESULT)),
    missingCount = sum(is.na(RESULT)),
    .by = CodeName
  ) %>%
  arrange(desc(missingCount), desc(measureCount)) %>%
  gt::gt() %>%
  gt::tab_header("Pre-DL imputation")
```

# Detection limit informed imputation
```{r dl-informedImp}
#| label: tbl-dlimputepost
#| tbl-cap: "Missing and nonmissing counts for each analyte after DL informed imputation."

df <- .dlImputation(df, imputeMethod = "uniform") %>%
  filter(
    # remove 2 secchi samples that have an unrelated flag
    !(is.na(RESULT) & Unified_Flag == "T")
  )

# expectedRows <- df %>%
#   unite(un, sampleDateTime, Latitude, Longitude, sampleDepth) %>%
#   mutate(wide_rows = length(unique(un))) %>%
#   distinct(wide_rows) %>%
#   pull(wide_rows)

df %>% 
  reframe(
    measureCount = sum(!is.na(RESULT)),
    missingCount = sum(is.na(RESULT)),
    #expectedMissing = expectedRows - measureCount,
    .by = CodeName
  ) %>%
  arrange(desc(missingCount), desc(measureCount)) %>%
  gt::gt() %>%
  gt::tab_header("Post DL imputation")

saveRDS(df, "postImputed.Rds")
```


# Pivoting from long to wide

## Exact match pivoting
```{r pivoting}
df_wide <- .exactPivot(df)


df_wide %>%
  reframe(across(-c(Latitude:SITE_ID, Chla_ugl), function(x) sum(is.na(x) & !is.na(Chla_ugl))))  %>%
  gt::gt() %>%
  gt::tab_header("Missing values with Chla observations, n=9003")
```

## Nearest Neighbor imputation
- depth cutoffs conditional on the sample depth
  - sample > 30m then window =  15m
  - else 5m window
- Next, we will vary and explore different time and horizontal thresholds
  
### 6 days 30km
```{r nnimputation}
# 1 degree ≈ 110.574 km
# 0.27 ≈ 30km
# 27.5 minutes for these three

start.time <- Sys.time()
testdf <- .imputeNearestMatchColumn(df_wide, Temp_c, dayThresh = 6, latlonThres = 0.27)
testdf <- .imputeNearestMatchColumn(testdf, DO_mgl, dayThresh = 6, latlonThres = 0.27)
testdf <- .imputeNearestMatchColumn(testdf, Tot_P_ugl, dayThresh = 6, latlonThres = 0.27)

# [ ] Look at 2 day  15 km threshold

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

# replaced 
before <- df_wide %>%
  reframe(across(c(Temp_c, DO_mgl, Tot_P_ugl), function(x) mean(is.na(x) & !is.na(Chla_ugl) )))
after <- testdf %>%
  reframe(across(c(Temp_c, DO_mgl, Tot_P_ugl), function(x) mean(is.na(x) & !is.na(Chla_ugl))))

bind_rows(before, after) %>%
  mutate(step = c("before", "after")) %>%
  gt::gt(caption  = "% Chla with missing before and after nearest neighbor imputation, n=9003")

df_wide %>%
  mutate(step = "before") %>%
  bind_rows(testdf) %>%
  mutate(step = ifelse(is.na(step), "after", step)) %>%
  pivot_longer(c(Temp_c, DO_mgl, Tot_P_ugl), names_to = "CodeName") %>%
  filter(value < 50) %>%
  ggplot(aes(x = value, col = step)) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~CodeName,  scales = "free")
```
- Takes 1.5 minutes total for Temp, DO, and TP
  - will potentially be longer for columns with greater missingness 
    - more matches to make
    - fewer boxes with an observation within
- 49 variables
  - 49 x 1.5 / 3  = 24.5 mins

### 2 days 15km
```{r nnimputation-2}
# 1 degree ≈ 110.574 km
# 0.27 ≈ 30km
# 1.5 minutes for these three
start.time <- Sys.time()
testdf <- .imputeNearestMatchColumn(df_wide, Temp_c, dayThresh = 2, latlonThres = 0.135)
testdf <- .imputeNearestMatchColumn(testdf, DO_mgl, dayThresh = 2, latlonThres = 0.135)
testdf <- .imputeNearestMatchColumn(testdf, Tot_P_ugl, dayThresh = 2, latlonThres = 0.135)

# replaced 
before <- df_wide %>%
  reframe(across(c(Temp_c, DO_mgl, Tot_P_ugl), function(x) mean(is.na(x) & !is.na(Chla_ugl) )))
after <- testdf %>%
  reframe(across(c(Temp_c, DO_mgl, Tot_P_ugl), function(x) mean(is.na(x) & !is.na(Chla_ugl))))

bind_rows(before, after) %>%
  mutate(step = c("before", "after")) %>%
  gt::gt(caption  = "% Chla with missing before and after nearest neighbor imputation, n=8998")

df_wide %>%
  mutate(step = "before") %>%
  bind_rows(testdf) %>%
  mutate(step = ifelse(is.na(step), "after", step)) %>%
  pivot_longer(c(Temp_c, DO_mgl, Tot_P_ugl), names_to = "CodeName") %>%
  filter(value < 50) %>%
  ggplot(aes(x = value, col = step)) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~CodeName,  scales = "free")
```



# Naive imputation
- roughly 2 minutes
```{r naiveImputation}
# Subset grab columns with not much worse missingness than chla
test <- df_wide[, colMeans(is.na(df_wide)) < mean(is.na(df_wide$Chla_ugl)) * 1.05]

# missForest doesn't like tibbles so convert to deprecated df
test <- test %>% 
  drop_na(Chla_ugl) %>% 
  select(-c(1:6)) %>%
  data.frame() %>%
  drop_na(Chla_ugl) #%>%
  #slice(1:1000)


# [ ] keep missing Chla obs for imputation (more information) then subset to just where Chla is nonmissing
# [ ] could stratify by near / offshore or seasonality
start.time <- Sys.time()
test2 <- missForest::missForest(test, variablewise = T)
#colMeans(is.na(test2[[2]]))
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken


test %>%
  mutate(observed = F) %>%
  bind_rows(test2$ximp) %>%
  mutate(observed = ifelse(observed, F, T)) %>%
  pivot_longer(-observed) %>%
  drop_na(value) %>%
  filter(sum(!is.na(value)) > 100, .by = name) %>%
  ggplot(aes(x = value, col = observed)) +
  geom_density() +
  facet_wrap(~name, scales = "free") +
  ggtitle("Marginal distributiosn before and after missForest")



length(sqrt(test2$OOBerror)) /
test %>% 
  reframe(across(everything(), function(x) sd(x, na.rm = T)))
```
- 6 minutes


# thermocline fit
```{r thermoViz}
thermos <- testdf %>%
  mutate(thermocline = 
    (sum(Temp_c > 15.5, na.rm = T) > 1) & 
    (sum(Temp_c < 5, na.rm = T) > 1), .by = c(sampleDateTime, SITE_ID))

thermos %>%
  ggplot(aes(y = sampleDepth, x = Temp_c, col = thermocline)) +
  geom_point() + 
  scale_y_reverse()

thermos <- thermos %>% filter(thermocline)

mod <- data.frame(
  "depth" = sort(unique(thermos$sampleDepth))
) %>%
  rowwise() %>%
  mutate(
    p1 = 22 - 18 * pgamma(depth, shape = 10, scale = 1.8),
    p2 = 22 - 18 * pgamma(depth, shape = 9, scale = 2),
    p3 = 22 - 18 * pgamma(depth, shape = 6, scale = 3),
    # p1 = 22 -pracma::gammainc(depth, a = 3)[[1]],
    # p2 = 22 -pracma::gammainc(depth, a = 4)[[1]],
    # p3 = -pracma::gammainc(depth, a = 5)[[1]],
    )


thermos %>%
  ggplot(aes(y = sampleDepth, x = Temp_c)) +
  geom_point() + 
  geom_line(data = mod, aes(y = depth, x = p1), col = "red", size=  2) + 
  geom_line(data = mod, aes(y = depth, x = p2), col = "blue", size=  2) + 
  geom_line(data = mod, aes(y = depth, x = p3), col = "green", size=  2) + 
  scale_y_reverse()
```

## thermocline numeric fit
```{r thermoFit}
#| eval: false

alpha <- 3.1
theta <- 0.1

partial_lgam <- function(alpha, theta, depths, iter) {
  depthsub <- depths[1:iter]
  ddepth <- diff(depthsub)
  depthsub <- depths[2:iter]
  answer <- cumsum(depthsub ^(alpha-1) * exp(-depthsub) * ddepth)
  return (answer) 
}

plot(pgamma(thermos$Temp_c, shape = 0.00002, rate = 0.000075))

optim(pgamma(1:14956/14956 , shape = 2, rate = 7.5) * ma + mi)
```